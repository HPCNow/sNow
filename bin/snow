#!/bin/bash
#set -xv
# This is the sNow! Command Line Interface 
# Developed by Jordi Blasco <jordi.blasco@hpcnow.com>
# For more information, visit the official website : www.hpcnow.com/snow
#

SNOWPATH=$(dirname "$0")
# Load the configuration
CONFIG_FILE=$SNOWPATH/../etc/snow.conf
SNOW_MODULES=$SNOWPATH/../etc/active-modules.conf
SELF_ACTIVE_MODULES=$(cat $SNOW_MODULES | grep -v ^# | cut -d= -f1 | gawk '{print $1}')
opt1=$1
opt2=$2
opt3=$3
opt4=$4
opt5=$5

if [[ -f $CONFIG_FILE ]]; then
    source $CONFIG_FILE
fi

if [[ -f $SNOW_MODULES ]]; then
    source $SNOW_MODULES
fi

if [[ -d $SNOWROOT/log ]]; then
    mkdir $SNOWROOT/log
fi

function shelp(){
echo " 
This is the sNow! Command Line Interface
Developed by Jordi Blasco <jordi.blasco@hpcnow.com>
For more information, visit the official website : www.hpcnow.com

Usage: snow [function] <option|module|server>

Function List:

    * config                       | updates the sNow! configuration based on the snow.conf, /etc/hosts and active-modules.conf
    * update tools                 | updates the sNow! Tools from the public HPCNow! GIT repo
    * update configspace           | updates configuration files from public git repo
    * update <module|server>       | updates specific module or server
    * create base                  | installs the basic software to deploy VMs, cluster filesystem nodes and compute nodes
    * create <module>              | installs specific module (Xen VM)
    * deploy <server>              | deploy specific server 
    * clone <server> <image_name>  | clone server with specific image file 
    * list                         | list current services and the status
    * takeover                     | migrates VMs and critical services to other nodes
    * boot <module|server>         | boot specific module or server
    * boot services                | boot all the services
    * boot cluster <clustername>   | boot all the compute nodes (by default 20 nodes at once)
    * reboot <module|server>       | reboot specific module or server
    * shutdown <module|server>     | shutdown specific module or server
    * destroy <module|server>      | force to stop specific module or server
    * console <module|server>      | console access to specific module or server
    * uptime <module|sever>        | shows uptime of specific module or server

Examples:

    snow update tools
    snow create base
    snow create ldap01
"
}

#function check_interfaces() {
#ip show ${BRIDGEMAP[xpub0]}
#}

function config() {
#check_interfaces
if ! [[ -f $SNOW_MODULES ]]; then
    echo "No $SNOW_MODULES found"
else
    cat $SNOWROOT/snow-tools/etc/snow.conf
    echo "==== Active Modules ===="
    cat $SNOWROOT/snow-tools/etc/active-modules.conf | grep -v ^# |  gawk '{print $0}'
fi
}

function update_tools() {
if ! [[ -d $SNOWROOT/snow-tools ]]; then
    mkdir -p $SNOWROOT
    cd $SNOWROOT
    git clone http://bitbucket.org/hpcnow/snow-tools.git
    cd -
else
    cd $SNOWROOT/snow-tools
    git pull http://bitbucket.org/hpcnow/snow-tools.git
fi 
}

function update_configspace() {
if ! [[ -d $SNOWROOT/snow-configspace  ]]; then
    mkdir -p $SNOWROOT
    cd $SNOWROOT
    git clone http://bitbucket.org/hpcnow/snow-configspace.git
    cd -
else
    cd $SNOWROOT/snow-configspace
    git pull http://bitbucket.org/hpcnow/snow-configspace.git
fi
}

function xen_create() {
    get_server_distribution $1 
    if (($IS_VM)) ; then
        echo "The VM $1 already exist, please use force option to overwrite the VM"
        exit 1
    else
        echo xen-create-image --config=/sNow/snow-tools/etc/xen-tools.conf --roledir=/sNow/snow-tools/etc/role.d                \
                    --hostname=$1 --mac=${VNAME[4]} --bridge=${VNAME[3]} --ip=${VNAME[2]} --gateway=${VNAME[5]} --netmask=${VNAME[6]} \
                    --role=udev,snow,${VNAME[0]} --accounts --copyhosts --genpass=0 $FORCE
    fi
}

function create_base() {
    if [[ "$opt3" == "force" ]]
    then 
        FORCE="--force"
    fi 
    xen_create deploy
}

function node_rank() {
    if [[ $1 =~ \] ]]; then
        NPREFIX=$(echo $1 | cut -d[ -f1)
        NRANK=($(echo $1 | cut -d[ -f2| cut -d] -f1|  sed -e "s/-/ /"))
        NLENG=$(echo ${NRANK[1]}-${NRANK[0]} | bc -l)
    else 
        NLENG=0
    fi
}

function deploy() {
    node_rank $1
    BLOCKN=${2:-$BLOCKN}
    BLOCKD=${3:-$BLOCKD}
    # In order to avoid power consumption peaks, the nodes needs to be booted in a blocks of few nodes with a delayed (5 seconds) timing between blocks
    # BlockN is the number of nodes to be iniciated at the same time (default should be 5)
    # BlockD is the delay between one block and the following one (default 5 seconds)
    # GNU Parallel : Pass $BLOCKN + Sleep $BLOCKD
    # echo "$NPREFIX $NLENG $BLOCKN $BLOCKD" 
    echo "This will install $1. All the data contained in these nodes will be removed"
    read -p "Are you sure? (y/n) : " -n 1 -r
    if [[ $REPLY =~ ^[Yy]$ ]]
    then
        echo
        echo "Setting up node : $1"
        ipmitool -I $IPMITYPE -H $1-bmc -U $IPMIUSER -P $IPMIPWD chassis bootparam set bootflag force_pxe
        ipmitool -I $IPMITYPE -H $1-bmc -U $IPMIUSER -P $IPMIPWD power cycle
        # Some IPMI versions doesn't work from the localhost, via IP allways works, so 2 minutes per block of nodes
        echo "Deploying node : $1 ... Please wait"
        sleep 120
        ipmitool -I $IPMITYPE -H $1-bmc -U $IPMIUSER -P $IPMIPWD chassis bootparam set bootflag force_disk
    else
        echo
        echo "Well done. It's better to be sure."
    fi
}

function update() {
    echo update
}

function list() {
    xm list $opt2
}

function takeover() {
    echo takeover
}

function boot() {
    get_server_distribution $1
    if (($IS_VM)) ; then
        xm create $SNOWROOT/snow-tools/etc/modules/$1-nfs.cfg
    else
        node_rank $1
        BLOCKN=${2:-$BLOCKN}
        BLOCKD=${3:-$BLOCKD}
        if (( $NLENG > 1 )); then
            #parallel --delay $BLOCKD -N $BLOCKN -j 4 echo "$NPREFIX{}-bmc" ::: $(eval echo "{${NRANK[0]}..${NRANK[1]}}")
            #exit 1
            parallel --delay $BLOCKD -N $BLOCKN -j 4 \
            ipmitool -I $IPMITYPE -H $NPREFIX{}-bmc -U $IPMIUSER -P $IPMIPWD chassis bootparam set bootflag force_disk \; \
            ipmitool -I $IPMITYPE -H $NPREFIX{}-bmc -U $IPMIUSER -P $IPMIPWD power up \
            ::: $(eval echo "{${NRANK[0]}..${NRANK[1]}}") 
        else 
            ipmitool -I $IPMITYPE -H $1-bmc -U $IPMIUSER -P $IPMIPWD chassis bootparam set bootflag force_disk
            ipmitool -I $IPMITYPE -H $1-bmc -U $IPMIUSER -P $IPMIPWD power up
        fi
    fi
}

function get_server_distribution(){
    node_rank $1
    if (( $NLENG > 1 )); then
        # VM ranks are not yet supported
        IS_VM=0
    else
        IS_VM=$(cat $SNOW_MODULES | gawk -v vm="^$1=" 'BEGIN{isvm=0}{if (match($1, vm)){isvm=1}}END{print isvm}')
    fi
}

function boot_services() {
    #get_server_distribution 
    for i in $(SELF_ACTIVE_MODULES)
    do 
        #ssh server[$i] xm create $SNOWROOT/etc/xen/$i.cfg
        xm create $SNOWROOT/etc/xen/$i.cfg
    done
}

function boot_cluster() {
    CLUSTERNAME=$1
    BLOCKN=${2:-$BLOCKN}
    BLOCKD=${3:-$BLOCKD}
    # In order to avoid power consumption peaks, the nodes needs to be booted in a blocks of few nodes with a delayed (5 seconds) timing between blocks 
    # BlockN is the number of nodes to be iniciated at the same time (default should be 5)
    # BlockD is the delay between one block and the following one (default 5 seconds)
    # GNU Parallel : Pass $BLOCKN + Sleep $BLOCKD
    echo boot_cluster 
}

function nreboot() {
    pdsh -w $1 reboot
}

function nshutdown() {
    pdsh -w $1 halt
}

function ndestroy() {
    get_server_distribution $1
    if $IS_WM ; then 
        xm destroy $1
    else
        ipmitool -I $IPMITYPE -H $1-bmc -U $IPMIUSER -P $IPMIPWD power down
    fi
}

function nconsole() {
    get_server_distribution $1
    if (($IS_VM)) ; then
        xm console $1
    else
        ipmitool -I $IPMITYPE -H $1-bmc -U $IPMIUSER -P $IPMIPWD sol deactivate
        sleep 1
        ipmitool -I $IPMITYPE -H $1-bmc -U $IPMIUSER -P $IPMIPWD sol activate
    fi
}

function nuptime() {
    pdsh -w $1 uptime 
}

#
# End Functions
#

#
# Start Cases
#
case $opt1 in
    config)
        config
    ;;
    update)
        case $opt2 in
            tools)
                update_tools
            ;;
            configspace)
                update_configspace
            ;;
            *)
                update $opt3
            ;;
        esac
    ;;
    deploy)
        deploy $opt2 $opt3 $opt4 $opt5
    ;;
    clone)
        clone $opt2 $opt3
    ;;
    create)
        case $opt2 in
            base)
                create_base
            ;;
            *)
                create $opt2
            ;;
        esac
    ;;
    list)
        list $opt2
    ;;
    takeover)
        takeover $opt2
    ;;
    boot)
        case $opt2 in
            services)  
                boot_services $opt3 
            ;;
            cluster)
                boot_cluster $opt3 $opt4 $opt5 
            ;;
            *)
                boot $opt2 $opt3 $opt4
            ;;
        esac
    ;;
    reboot)
        nreboot $opt2
    ;;
    shutdown)
        nshutdown $opt2
    ;;
    destroy)
        ndestroy $opt2
    ;;
    console)
        nconsole $opt2
    ;;
    uptime)
        nuptime $opt2
    ;;
    help|\?)
      shelp
      ;;
  esac

#
# End Cases
#

#
# Log the sNow! activity
#

#echo "$(date)    $USER    $@" >> $SNOWROOT/log/snow_actions.log 
