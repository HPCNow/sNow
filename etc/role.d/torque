#!/bin/bash
# Configure the new image for sNow! HPC suite
# Developed by Jordi Blasco <jordi.blasco@hpcnow.com>
# For more information, visit the official website : www.hpcnow.com/snow
#

# Now! roles are shell scripts easy to develop and to understand
# Keep in mind the following tips and tricks which will help you to develop new roles:
# (1) Use enviroment variables defined in snow.conf, and extend them if you need new 
#     variables to work with
# (2) When you generate a new configuration file, remember to copy the file in the 
#     deployed system and also /sNow/snow-confispace/system_files. If there is a file 
#     in this path, avoid to overwrite it and used it to setup your new system. i
#     This will help to integrate Continous Integration into your system.
# (3) Place comments inside complex sections of the code in order to help people to understand what you are doing
# (4) Use chroot ${prefix} to run commands inside the new deployed system
# (5) Use installDebianPackage ${prefix} to install packages
# (6) Use variables inside the templates easy to recognise and replace __NAME_OF_VARIABLE__
# (7) Use sed with pipe symbols rather than slash symbols. This will help you to replace unix path.

prefix=$1

#  Source our common functions - this will let us install a Debian package.
if [[ -e /usr/share/xen-tools/common.sh ]]; then
    . /usr/share/xen-tools/common.sh
else
    echo "Installation problem"
fi

# Load sNow! configuration
if [[ -e /sNow/snow-tools/etc/snow.conf ]]; then
    source /sNow/snow-tools/etc/snow.conf
else
    error_msg  "The /sNow/snow-tools/etc/snow.conf is not available."
    error_exit "Please use the /sNow/snow-tools/etc/snow.conf-example to setup your environment."
fi
# Load sNow! functions
if [[ -f /sNow/snow-tools/share/common.sh ]]; then
    source /sNow/snow-tools/share/common.sh
    get_os_distro
    architecture_identification
fi

##############     EVALUATE WHO PROVIDES THE SERVICE (SITE, SNOW or BOTH)     ###############
# Setup New Serivce Client
# get the IP of the server offering this service
SNOW_TORQUE_MASTER=$(gawk '{if($2 ~ /torque/){print $4}}' $SNOW_TOOL/etc/domains.conf)
# If the site is offering the server already and sNow! is also deploying the server,
# then we asume that sNow server will act as a proxy or relay server (usefull to avoid DOS of performance degradation)
# Otherwise, we will use the only available service.
if  [[ -n "$SNOW_TORQUE_MASTER" ]]; then 
    TORQUE_VERSION=6.1.0
    TORQUE_MASTER=$SNOW_TORQUE_MASTER
    #download http://www.adaptivecomputing.com/download/torque/torque-${TORQUE_VERSION}.tar.gz ${prefix}/root/
    download "http://wpfilebase.s3.amazonaws.com/torque/torque-${TORQUE_VERSION}.tar.gz" "${prefix}/root/"
    installDebianPackage ${prefix} build-essential hwloc libxml2-dev libtool zlib1g-dev libboost-dev libcgroup-dev libhwloc-dev pkg-config libssl-dev
    cd ${prefix}/root
    tar -zxvf torque-${TORQUE_VERSION}.tar.gz
    chroot ${prefix} /root/torque-${TORQUE_VERSION}/configure --build=x86_64 --host=x86_64 ‑‑enable‑cgroups 
    chroot ${prefix} /root/torque-${TORQUE_VERSION}/configure --build=x86_64 --host=x86_64 ‑‑enable‑cgroups --prefix=/usr/local/torque/${TORQUE_VERSION}
    #chroot ${prefix} /usr/bin/make --directory=/root/torque-${TORQUE_VERSION} PKGNAME=${TORQUE_VERSION} packages
    chroot ${prefix} /usr/bin/make PKGNAME=${TORQUE_VERSION} packages
    chroot ${prefix} /bin/cp -p torque-${TORQUE_VERSION}-*.sh /root/torque-${TORQUE_VERSION}/
    ##chroot ${prefix} /usr/bin/libtool --finish /usr/local/torque/${TORQUE_VERSION}/lib 
    chroot ${prefix} /root/torque-${TORQUE_VERSION}/torque-${TORQUE_VERSION}-server-linux-x86_64.sh --install
    chroot ${prefix} /root/torque-${TORQUE_VERSION}/torque-${TORQUE_VERSION}-mom-linux-x86_64.sh --install
    chroot ${prefix} /root/torque-${TORQUE_VERSION}/torque-${TORQUE_VERSION}-clients-linux-x86_64.sh --install
    chroot ${prefix} /root/torque-${TORQUE_VERSION}/torque-${TORQUE_VERSION}-devel-linux-x86_64.sh --install
    chroot ${prefix} /root/torque-${TORQUE_VERSION}/torque-${TORQUE_VERSION}-doc-linux-x86_64.sh --install
    #chroot ${prefix} /usr/local/torque/${TORQUE_VERSION}/sbin/pbs_server -t create -f 
    #chroot ${prefix} /usr/local/torque/${TORQUE_VERSION}/sbin/trqauthd start
    #chroot ${prefix} /usr/local/torque/${TORQUE_VERSION}/bin/qmgr -c "set server scheduling=true"
    #chroot ${prefix} /usr/local/torque/${TORQUE_VERSION}/bin/qmgr -c "create queue batch queue_type=execution"
    #chroot ${prefix} /usr/local/torque/${TORQUE_VERSION}/bin/qmgr -c "set queue batch started=true"
    #chroot ${prefix} /usr/local/torque/${TORQUE_VERSION}/bin/qmgr -c "set queue batch enabled=true"
    #chroot ${prefix} /usr/local/torque/${TORQUE_VERSION}/bin/qmgr -c "set queue batch resources_default.nodes=1"
    #chroot ${prefix} /usr/local/torque/${TORQUE_VERSION}/bin/qmgr -c "set queue batch resources_default.walltime=3600"
    #chroot ${prefix} /usr/local/torque/${TORQUE_VERSION}/bin/qmgr -c "set server default_queue=batch"
fi

