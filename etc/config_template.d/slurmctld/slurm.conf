# slurm.conf file generated by configurator.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
#
ControlMachine=__CONTROL_MACHINE__
#ControlAddr=
#BackupController=__BACKUP_CONTROLLER__
#BackupAddr=
# 
AuthType=auth/munge
CacheGroups=0
#CheckpointType=checkpoint/blcr
CryptoType=crypto/munge
DisableRootJobs=NO 
#EnforcePartLimits=NO 
Epilog=/etc/slurm/epilog/job.sh
#EpilogSlurmctld= 
#FirstJobId=1
#MaxJobId=
#GresTypes=
#GroupUpdateForce=0 
#GroupUpdateTime=600 
#JobCheckpointDir=/scratch/checkpoint
#JobCredentialPrivateKey=
#JobCredentialPublicCertificate=
#JobFileAppend=0 
#JobRequeue=1 
JobSubmitPlugins=all_partitions
#JobSubmitPlugins=lua
#KillOnBadExit=0 
#LaunchType=launch/slurm 
Licenses=__LICENSES__
MailProg=/bin/mail 
MaxJobCount=50000 
#MaxStepCount=40000 
#MaxTasksPerNode=128 
MpiDefault=none
MpiParams=ports=12000-12099
#PluginDir= 
#PlugStackConfig= 
#PrivateData=jobs 
ProctrackType=proctrack/cgroup
Prolog=/etc/slurm/prolog/job.sh
#PrologSlurmctld= 
#PropagatePrioProcess=0 
PropagateResourceLimits=NONE
#PropagateResourceLimitsExcept=MEMLOCK,CPU 
#RebootProgram= 
ReturnToService=1
#SallocDefaultCommand="srun -n1 -N1 --mem-per-cpu=0 --pty --preserve-env --mpi=none $SHELL" 
SallocDefaultCommand="srun -n1 -N1 --mem-per-cpu=0 --pty --mpi=none $SHELL" 
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmctldPort=6817
SlurmdPidFile=/var/run/slurmd.pid
SlurmdPort=6818
SlurmdSpoolDir=/var/spool/slurmd
#SlurmUser=slurm
SlurmdUser=root 
SrunEpilog=/etc/slurm/epilog/srun.sh
SrunProlog=/etc/slurm/prolog/srun.sh
StateSaveLocation=/var/spool/slurm
#StateSaveLocation=/var/spool
SwitchType=switch/none
TaskEpilog=/etc/slurm/epilog/task.sh
TaskPlugin=task/cgroup
#TaskPluginParam=
TaskProlog=/etc/slurm/prolog/task.sh
TopologyPlugin=topology/tree 
TmpFS=/tmp
#TrackWCKey=no 
#TreeWidth= 
#UnkillableStepProgram= 
#UsePAM=1
# 
# 
# TIMERS 
BatchStartTimeout=300
#CompleteWait=0 
#EpilogMsgTime=2000 
#GetEnvTimeout=2 
#HealthCheckInterval=300 
#HealthCheckProgram=/usr/sbin/nhc
InactiveLimit=120
KillWait=30
MessageTimeout=20 
#ResvOverRun=0 
MinJobAge=300
#OverTimeLimit=0 
SlurmctldTimeout=120
SlurmdTimeout=300
#UnkillableStepTimeout=60 
#VSizeFactor=0 
Waittime=0
# 
# 
# SCHEDULING 
DefMemPerCPU=1024
FastSchedule=1
#MaxMemPerCPU=0 
#SchedulerRootFilter=1 
#SchedulerTimeSlice=30 
SchedulerType=sched/backfill
SchedulerParameters=max_job_bf=50,defer,default_queue_depth=100,kill_invalid_depend
SchedulerPort=7321
SelectType=select/cons_res
SelectTypeParameters=CR_CPU_Memory
# 
# 
# JOB PRIORITY 
PriorityFlags=DEPTH_OBLIVIOUS,SMALL_RELATIVE_TO_TIME
PriorityType=priority/multifactor
PriorityDecayHalfLife=14-0 
#PriorityCalcPeriod= 
PriorityFavorSmall=NO 
PriorityMaxAge=7-0 
#PriorityUsageResetPeriod=MONTHLY 
PriorityWeightAge=1000 
PriorityWeightFairshare=40000 
PriorityWeightJobSize=2000 
PriorityWeightPartition=4000
PriorityWeightQOS=0 
#
#
# PREEMPTION
PreemptType=preempt/partition_prio
PreemptMode=suspend,gang
# 
# 
# LOGGING AND ACCOUNTING 
#__INCLUDE_LOGGING_AND_ACCOUNTING__
# 
# 
# POWER SAVE SUPPORT FOR IDLE NODES (optional) 
#SuspendProgram= 
#ResumeProgram= 
#SuspendTimeout= 
#ResumeTimeout= 
#ResumeRate= 
#SuspendExcNodes= 
#SuspendExcParts= 
#SuspendRate= 
#SuspendTime= 
# 
# 
# COMPUTE NODES 
NodeName=__COMPUTE_NODES__  RealMemory=__COMPUTE_NODES_MEM__ Sockets=__COMPUTE_NODES_SOCKETS__ CoresPerSocket=__COMPUTE_NODES_CORESxSOCKET__ ThreadsPerCore=__COMPUTE_NODES_THREADS__ State=UNKNOWN
# PARTITIONS
PartitionName=low     Nodes=__COMPUTE_NODES__  Default=YES Shared=FORCE:1 Priority=25  MaxTime=168:00:00 PreemptMode=suspend
PartitionName=medium  Nodes=__COMPUTE_NODES__  Default=NO  Shared=FORCE:1 Priority=20  MaxTime=72:00:00  PreemptMode=off
PartitionName=requeue Nodes=__COMPUTE_NODES__  Default=NO  Shared=NO      Priority=50  MaxTime=24:00:00  PreemptMode=requeue    GraceTime=120
PartitionName=high    Nodes=__COMPUTE_NODES__  Default=NO  Shared=FORCE:1 Priority=100 MaxTime=6:00:00   PreemptMode=off
